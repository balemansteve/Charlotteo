import openai
import json
from app.core.config import settings
from app.services.prompt_builder import PromptBuilder
from app.services.function_definitions import functions
from app.services.function_executor import FunctionExecutor

class OpenAIClient:
    """
    Clase para interactuar con la API de OpenAI.
    """
    def __init__(self):
        openai.api_key = settings.OPENAI_API_KEY
        self.model = "gpt-4o"
        self.temperature = 0.3
        self.prompt_builder = PromptBuilder()
        self.executor = FunctionExecutor()

    def send_prompt(self, user_message: str):
        """
        Env√≠a un prompt a OpenAI, maneja function calling y devuelve la respuesta final al usuario.
        """
        # SYSTEM PROMPT ‚Üí Define el formato deseado para las respuestas
        system_prompt = {
    "role": "system",
    "content": """Eres un asistente t√©cnico de VMware especializado en interpretar datos de rendimiento.

Cuando recibas m√©tricas t√©cnicas (como uso de CPU), responde en este formato:

1. Resumen breve (1 l√≠nea).
2. Lista de hosts o VMs con:
   - nombre
   - uso de CPU en porcentaje
   - nivel de severidad visual:
     üü¢ saludable (‚â§ 70%)
     üü† moderado (71‚Äì85%)
     üî¥ alto (> 85%)
3. Conclusi√≥n o recomendaci√≥n si aplica.

Utiliza saltos de l√≠nea, emojis y evita responder literalmente el JSON.
"""
        }

        # Construir el mensaje del usuario con el prompt optimizado
        messages = [
            system_prompt,
            {"role": "user", "content": self.prompt_builder.build_prompt(user_message)}
        ]

        # Primer request: detectar si se necesita llamar una funci√≥n
        response = openai.ChatCompletion.create(
            model=self.model,
            messages=messages,
            temperature=self.temperature,
            functions=functions,
            function_call="auto"
        )

        message = response["choices"][0]["message"]

        if message.get("function_call"):
            function_name = message["function_call"]["name"]
            arguments = json.loads(message["function_call"]["arguments"])

            # Ejecutar la funci√≥n
            function_result = self.executor.execute(function_name, arguments)

            # Reenviar a OpenAI con los resultados t√©cnicos
            messages.append(message)  # funci√≥n que pidi√≥
            messages.append({
                "role": "function",
                "name": function_name,
                "content": json.dumps(function_result)
            })

            followup = openai.ChatCompletion.create(
                model=self.model,
                messages=messages,
                temperature=self.temperature
            )

            return followup["choices"][0]["message"]["content"]

        else:
            return message["content"]
